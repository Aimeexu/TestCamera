//
//  CaptureEngine.m
//  VideoRecord
//
//  Created by Jessica on 11/15/16.
//  Copyright Â© 2016 .inc. All rights reserved.
//

#import "CaptureEngine.h"
#import "CaptureEncoder.h"
#import <Photos/Photos.h>

@interface CaptureEngine()<AVCaptureAudioDataOutputSampleBufferDelegate,AVCaptureVideoDataOutputSampleBufferDelegate,AVCaptureMetadataOutputObjectsDelegate>
{
    AVCaptureVideoPreviewLayer *_layer;
    int _audioChannel;//ä¿¡é“
    Float64 _sampleRate;//é‡‡æ ·çŽ‡
    NSInteger _height;//è§†é¢‘åˆ†è¾¨çŽ‡é«˜
    NSInteger _width;//è§†é¢‘åˆ†è¾¨çŽ‡å®½

    CMTime _timeOffset;//æ—¶é—´åç§»
    CMTime _lastVideoTime;//ä¸Šæ¬¡å½•åˆ¶è§†é¢‘çš„æ—¶é—´
    CMTime _lastAudioTime;//ä¸Šæ¬¡å½•åˆ¶çš„éŸ³é¢‘çš„æ—¶é—´
}

@property (nonatomic, strong) AVCaptureSession *session;

//ä¿å­˜å½“å‰å­˜åˆ°è§†é¢‘çš„åå­—
@property (nonatomic, copy) NSString *videoName;


@property (nonatomic, strong) AVCaptureDeviceInput *frontCameraInput;//å‰ç½®æ‘„åƒå¤´è¾“å…¥
@property (nonatomic, strong) AVCaptureDeviceInput *backCameraInput;//åŽç½®æ‘„åƒå¤´è¾“å…¥
@property (nonatomic, strong) AVCaptureDeviceInput *micphoneInput;//micphoneè¾“å…¥

@property (nonatomic, strong) AVCaptureVideoDataOutput *videoDataOut;//è§†é¢‘è¾“å‡º
@property (nonatomic, strong) AVCaptureAudioDataOutput *audioDataOut;//éŸ³é¢‘è¾“å‡º
@property (nonatomic, strong) AVCaptureMetadataOutput *medaDataOut;//å…ƒæ•°æ®è¾“å‡º

@property (nonatomic, strong) dispatch_queue_t queue;//éŸ³è§†é¢‘å¤„ç†çš„é˜Ÿåˆ—

@property (nonatomic, strong) CaptureEncoder *encoder;

@property (nonatomic, strong) AVCaptureConnection *videoConnection;//è§†é¢‘è¿žæŽ¥å™¨
@property (nonatomic, strong) AVCaptureConnection *audioConnection;//éŸ³é¢‘è¿žæŽ¥å™¨
@property (nonatomic, strong) AVCaptureConnection *metaDataConnection;//å…ƒæ•°æ®è¿žæœºå™¨

@property (nonatomic, strong) UIView *faceTrackView;
@property (nonatomic, strong) NSMutableArray *faceids;

//å½“å‰æ‘„åƒå¤´æ˜¯ä¸æ˜¯å‰ç½®æ‘„åƒå¤´
@property (nonatomic, assign) BOOL isDevicePositionFront;

@end

@implementation CaptureEngine

-(NSMutableArray *)faceids{
    if (_faceids == nil) {
        _faceids = [NSMutableArray array];
    }
    return _faceids;
}

-(UIView *)faceTrackView{
    if (_faceTrackView == nil) {
        _faceTrackView = [[UIView alloc] initWithFrame:CGRectMake(0, 0, 44, 44)];
        _faceTrackView.backgroundColor = [UIColor colorWithRed:1 green:0 blue:0 alpha:0.3];
    }
    return _faceTrackView;
}


//åˆå§‹åŒ–é»˜è®¤å€¼,600så½•åˆ¶æ—¶é—´
-(instancetype)init{
    if (self == [super init]) {
        if (!self.maxRecordTime) {
            self.maxRecordTime = 600.0;
        }
    }
    return self;
}

//éŸ³é¢‘è¿žæŽ¥å™¨
-(AVCaptureConnection *)audioConnection{
    if (_audioConnection == nil) {
        _audioConnection = [self.audioDataOut connectionWithMediaType:AVMediaTypeAudio];
    }
    return _audioConnection;
}

//è§†é¢‘è¿žæŽ¥å™¨
-(AVCaptureConnection *)videoConnection{
    if (_videoConnection == nil) {
        _videoConnection = [self.videoDataOut connectionWithMediaType:AVMediaTypeVideo];
    }
    return _videoConnection;
}

//é˜Ÿåˆ—
-(dispatch_queue_t)queue{
    if (_queue == nil) {
        _queue = dispatch_queue_create("com.ppd.capturevideo.queue", DISPATCH_QUEUE_SERIAL);
    }
    return _queue;
}

//è¾“å‡º
-(AVCaptureVideoDataOutput *)videoDataOut{
    if (_videoDataOut == nil) {
        _videoDataOut = [[AVCaptureVideoDataOutput alloc] init];
        [_videoDataOut setSampleBufferDelegate:self queue:self.queue];
        NSDictionary *setting = [NSDictionary dictionaryWithObjectsAndKeys: [NSNumber numberWithInt:kCVPixelFormatType_420YpCbCr8BiPlanarVideoRange], kCVPixelBufferPixelFormatTypeKey,nil];
        _videoDataOut.videoSettings = setting;
    }
    return _videoDataOut;
}

-(AVCaptureAudioDataOutput *)audioDataOut{
    if (_audioDataOut == nil) {
        _audioDataOut = [[AVCaptureAudioDataOutput alloc] init];
        [_audioDataOut setSampleBufferDelegate:self queue:self.queue];
    }
    return _audioDataOut;
}

-(AVCaptureMetadataOutput *)medaDataOut{
    if (_medaDataOut == nil) {
        _medaDataOut = [[AVCaptureMetadataOutput alloc] init];
        [_medaDataOut setMetadataObjectsDelegate:self queue:self.queue];
    }
    return _medaDataOut;
}

//æ‘„åƒå¤´è¾“å…¥
-(AVCaptureDeviceInput *)backCameraInput{
    if (_backCameraInput == nil) {
        NSError *error;
        _backCameraInput = [[AVCaptureDeviceInput  alloc] initWithDevice:[self cameroWithPosition:AVCaptureDevicePositionBack] error:&error];
        if (error) {
            NSLog(@"åŽç½®æ‘„åƒå¤´èŽ·å–å¤±è´¥");
        }
    }
    self.isDevicePositionFront = NO;
    return _backCameraInput;
}

-(AVCaptureDeviceInput *)frontCameraInput{
    if (_frontCameraInput == nil) {
        NSError *error;
        _frontCameraInput = [[AVCaptureDeviceInput alloc] initWithDevice:[self cameroWithPosition:AVCaptureDevicePositionFront] error:&error];
        if (error) {
            NSLog(@"å‰ç½®æ‘„åƒå¤´èŽ·å–å¤±è´¥");
        }
    }
    self.isDevicePositionFront = YES;
    return _frontCameraInput;
}

-(AVCaptureDeviceInput *)micphoneInput{
    if (_micphoneInput == nil) {
        AVCaptureDevice *mic = [AVCaptureDevice defaultDeviceWithMediaType:AVMediaTypeAudio];
        NSError *error;
        _micphoneInput = [AVCaptureDeviceInput deviceInputWithDevice:mic error:&error];
        if (error) {
            NSLog(@"èŽ·å–micphoneå¤±è´¥");
        }
    }
    return _micphoneInput;
}

//èŽ·å–å¯ç”¨çš„æ‘„åƒå¤´
-(AVCaptureDevice *)cameroWithPosition:(AVCaptureDevicePosition)position{

    if ([[UIDevice currentDevice].systemVersion floatValue] >= 10.0) {
        AVCaptureDeviceDiscoverySession *dissession = [AVCaptureDeviceDiscoverySession discoverySessionWithDeviceTypes:@[AVCaptureDeviceTypeBuiltInDuoCamera,AVCaptureDeviceTypeBuiltInTelephotoCamera,AVCaptureDeviceTypeBuiltInWideAngleCamera] mediaType:AVMediaTypeVideo position:position];
        for (AVCaptureDevice *device in dissession.devices) {
            if ([device position] == position ) {
                return device;
            }
        }
    }else{
        NSArray *devices = [AVCaptureDevice devicesWithMediaType:AVMediaTypeVideo];
        for (AVCaptureDevice *device in devices) {
            if ([device position] == position) {
                return device;
            }
        }
    }
    return nil;
}

-(AVCaptureSession *)session{
    if (_session == nil) {
        _session = [[AVCaptureSession alloc] init];
        if ([_session canSetSessionPreset:AVCaptureSessionPresetMedium]) {
            _session.sessionPreset = AVCaptureSessionPresetMedium;
        }

        //æ·»åŠ è¾“å…¥-----é»˜è®¤backæ‘„åƒå¤´
        if ([_session canAddInput:self.frontCameraInput]) {
            [_session addInput:self.frontCameraInput];
        }

        if ([_session canAddInput:self.micphoneInput]) {
            [_session addInput:self.micphoneInput];
        }

        //æ·»åŠ è¾“å‡º--------------
        if ([_session canAddOutput:self.audioDataOut]) {
            [_session addOutput:self.audioDataOut];
            self.audioConnection = [self.audioDataOut connectionWithMediaType:AVMediaTypeAudio];
        }

        if ([_session canAddOutput:self.videoDataOut]) {
            [_session addOutput:self.videoDataOut];
            self.videoConnection =  [self.videoDataOut connectionWithMediaType:AVMediaTypeVideo];

            NSInteger widtdh = [UIScreen mainScreen].bounds.size.width;
            NSInteger height = [UIScreen mainScreen].bounds.size.height;

            _width = (widtdh%4) == 0 ? widtdh:(widtdh-widtdh%4);
            _height = (height%4) == 0 ? height:(height-height%4);
        }
        
        //è§£å†³å‰ç½®æ‘„åƒå¤´å½•åˆ¶è§†é¢‘å·¦å³é¢ å€’é—®é¢˜
        [self videoMirored];
        //è®¾ç½®å½•è§†é¢‘çš„æ–¹å‘
        self.videoConnection.videoOrientation = [self videoOrientationFromCurrentDeviceOrientation];
        
         [[NSNotificationCenter defaultCenter] addObserver:self selector:@selector(statusBarOrientationChange:) name:UIApplicationDidChangeStatusBarOrientationNotification object:nil];
    }
    return _session;
}

- (void)statusBarOrientationChange:(NSNotification *)notification {
    //è®¾ç½®å½•è§†é¢‘çš„æ–¹å‘
    self.videoConnection.videoOrientation = [self videoOrientationFromCurrentDeviceOrientation];
    self.prewView.connection.videoOrientation = [self videoOrientationFromCurrentDeviceOrientation];
}

/**
 è§£å†³å‰ç½®æ‘„åƒå¤´å½•åˆ¶è§†é¢‘å·¦å³é¢ å€’é—®é¢˜                                               
 */
- (void)videoMirored {
    AVCaptureSession* session = (AVCaptureSession *)self.session;
    for (AVCaptureVideoDataOutput* output in session.outputs) {
        
        for (AVCaptureConnection * av in output.connections) {
            
//            av.videoOrientation = [self videoOrientationFromCurrentDeviceOrientation];
            
            if (self.isDevicePositionFront) {
                
                if (av.supportsVideoMirroring) {
                    
                    av.videoMirrored = YES;
                }
            }
        }
    }
}

/**
 è®¾ç½®å½•åˆ¶è§†é¢‘æ–¹å‘

 @return ipadä¸Šåªå…è®¸æ¨ªå±
 */
- (AVCaptureVideoOrientation) videoOrientationFromCurrentDeviceOrientation {
    UIInterfaceOrientation interfaceOrientation = UIApplication.sharedApplication.statusBarOrientation;
    switch (interfaceOrientation) {

        case UIInterfaceOrientationPortrait: {
            return AVCaptureVideoOrientationPortrait;
        }

        default:
            return AVCaptureVideoOrientationPortrait;
    }
}

/**
 æ˜¾ç¤ºviewä¸Šè§†é¢‘æ–¹å‘

 @return ipadä¸Šåªå…è®¸æ¨ªå±
 */
- (AVCaptureVideoPreviewLayer *)prewView{
    if (_layer == nil) {
        _layer = [[AVCaptureVideoPreviewLayer alloc] initWithSession:self.session];
        _layer.videoGravity = AVLayerVideoGravityResizeAspectFill;
        _layer.connection.videoOrientation = [self videoOrientationFromCurrentDeviceOrientation];
    }
    return _layer;
}

//è®¾ç½®éŸ³é¢‘æ ¼å¼
-(void)configAudioFormat:(CMSampleBufferRef)sampleBuffer{
    CMFormatDescriptionRef ref = CMSampleBufferGetFormatDescription(sampleBuffer);
    const AudioStreamBasicDescription *audioDesc = CMAudioFormatDescriptionGetStreamBasicDescription(ref);
    _sampleRate = audioDesc->mSampleRate;
    _audioChannel = audioDesc->mChannelsPerFrame;
}

//è®¡ç®—æ—¶é—´å·®
-(void)timeOffsetWithSampleBuffer:(CMSampleBufferRef)sampleBuffer isVideo:(BOOL)isVideo{
    CMTime presentTime = CMSampleBufferGetPresentationTimeStamp(sampleBuffer);
    CMTime lastTime = isVideo ? _lastVideoTime : _lastAudioTime;
    if (lastTime.flags & kCMTimeFlags_Valid) {
        if (_timeOffset.flags & kCMTimeFlags_Valid) {
            presentTime = CMTimeSubtract(presentTime, lastTime);
        }

        CMTime offset = CMTimeSubtract(presentTime, lastTime);
        if (_timeOffset.value == 0) {
            _timeOffset = offset;
        }else{
            _timeOffset = CMTimeAdd(_timeOffset, offset);
        }
    }

    _lastVideoTime.flags = 0;
    _lastAudioTime.flags = 0;
}

//è®¡ç®—ä¸Šæ¬¡å½•åˆ¶çš„æ—¶é—´
-(void)getLastTimeWithSampleBuffer:(CMSampleBufferRef)sampleBuffer isVideo:(BOOL)isVideo{
    CMTime present = CMSampleBufferGetPresentationTimeStamp(sampleBuffer);
    CMTime duration = CMSampleBufferGetDuration(sampleBuffer);
    if (duration.value > 0) {
        present = CMTimeAdd(present, duration);
    }
    if (isVideo) {
        _lastVideoTime = present;
    }else{
        _lastAudioTime = present;
    }
}

//æ”¯æŒäººè„¸è¯†åˆ«çš„ä»£ç†æ–¹æ³•
-(void)captureOutput:(AVCaptureOutput *)captureOutput didOutputMetadataObjects:(NSArray *)metadataObjects fromConnection:(AVCaptureConnection *)connection{
    if (metadataObjects.count) {
        NSLog(@"äººè„¸ä¸ªæ•°-----%@",metadataObjects);
        for (AVMetadataFaceObject *obj in metadataObjects) {

            for (NSNumber *faceid in self.faceids) {

                if (faceid == [NSNumber numberWithInteger:obj.faceID]) {
                    break;
                }else{
                    [self.faceids addObject:[NSNumber numberWithInteger:obj.faceID]];
                }
            }

            CGRect rect = obj.bounds;

            //åæ ‡ç³»è½¬æ¢-90
            self.faceTrackView.frame = CGRectMake([UIScreen mainScreen].bounds.size.width*(1 - rect.origin.y - rect.size.height/2.0), [UIScreen mainScreen].bounds.size.height*(rect.origin.x + rect.size.width/2.0), rect.size.height * [UIScreen mainScreen].bounds.size.width, [UIScreen mainScreen].bounds.size.height * rect.size.width);
        }
    }else{
        [[NSNotificationCenter defaultCenter] postNotificationName:@"noface" object:nil];
    }
}

//ä»£ç†æ–¹æ³•
-(void)captureOutput:(AVCaptureOutput *)captureOutput didOutputSampleBuffer:(CMSampleBufferRef)sampleBuffer fromConnection:(AVCaptureConnection *)connection{
    BOOL isVideo = YES;
    @synchronized (self) {
        if (captureOutput != self.videoDataOut) {
            isVideo = NO;
        }

        if (!self.isCapturing || self.isPaused) {
            return;
        }

        //éŸ³é¢‘
        if ((self.encoder == nil) && !isVideo) {
            [self configAudioFormat:sampleBuffer];
//            NSString *name = [self formatNameWithType:@"mp4"];
//            self.videoPath = [[self getVideoPath] stringByAppendingPathComponent:name];
            self.encoder = [CaptureEncoder encoderWithPath:self.videoPath height:_height width:_width audioChannel:_audioChannel samlpleRate:_sampleRate];
        }

        //æ˜¯å¦ä¸­æ–­è¿‡
        if (self.isBreaked || self.isPaused) {
            //NSLog(@"ä¸­æ–­è¿‡");
            if (isVideo) {
                return;
            }

            self.isBreaked = NO;

            //è®¡ç®—æš‚åœçš„æ—¶é—´åç§»
            [self timeOffsetWithSampleBuffer:sampleBuffer isVideo:isVideo];
        }else{
            //NSLog(@"æ²¡æœ‰ä¸­æ–­è¿‡");
        }

        //å¯¹sampleBufferå¼•ç”¨è®¡æ•°,é˜²æ­¢åœ¨ä¿®æ”¹çš„æ—¶å€™è¢«é‡Šæ”¾
        CFRetain(sampleBuffer);
        if (_timeOffset.value > 0) {
            CFRelease(sampleBuffer);

            //è°ƒæ•´æ—¶é—´åŽçš„sampleBuffer
            sampleBuffer = [self adjustSampleBuffer:sampleBuffer offsetTime:_timeOffset];

        }

        //ä¸Šæ¬¡çš„å½•åˆ¶æ—¶é—´
        [self getLastTimeWithSampleBuffer:sampleBuffer isVideo:isVideo];
    }

    CMTime presentTime = CMSampleBufferGetPresentationTimeStamp(sampleBuffer);
    if (self.startTime.value == 0) {
        self.startTime = presentTime;
    }
    CMTime sub = CMTimeSubtract(presentTime, self.startTime);
    self.currentTime = CMTimeGetSeconds(sub);

    //å½•åˆ¶å®Œæˆçš„æ—¶é—´
    if (self.currentTime >= self.maxRecordTime) {
        if ((self.currentTime - self.maxRecordTime) < 0.1) {
            //è®¡ç®—è¿›åº¦å¹¶æ˜¾ç¤º
            //NSLog(@"å®Œæˆäº†çš„-----è¿›åº¦-------------%f",self.currentTime/self.maxRecordTime);
            //NSLog(@"å®Œæˆäº†çš„---å½“å‰æ—¶é—´------%f",self.currentTime);
        }
        return;
    }
        //è®¡ç®—è¿›åº¦å¹¶æ˜¾ç¤º
       // NSLog(@"æœªå½•åˆ¶å®Œæˆ-----è¿›åº¦-------------%f",self.currentTime/self.maxRecordTime);
        //NSLog(@"æœªå½•åˆ¶å®Œæˆ----------å½“å‰æ—¶é—´------%f",self.currentTime);


    //è¿›è¡Œæ•°æ®ç¼–ç 
    [self.encoder encodeBuffer:sampleBuffer isVideo:isVideo completion:^(BOOL flag) {
        if (flag) {
            //NSLog(@"ç¼–ç æ•°æ®æˆåŠŸ");
        }
    }];
    
    CFRelease(sampleBuffer);
}

//è°ƒæ•´æ•°æ®çš„æ—¶é—´
-(CMSampleBufferRef)adjustSampleBuffer:(CMSampleBufferRef)sampleBuffer offsetTime:(CMTime)offsetTime{
    CMItemCount count;
    CMSampleBufferGetSampleTimingInfoArray(sampleBuffer, 0, nil, &count);
    CMSampleTimingInfo *info = malloc(sizeof(CMSampleTimingInfo) * count);
    CMSampleBufferGetSampleTimingInfoArray(sampleBuffer, count, info, &count);
    for (CMItemCount i = 0; i < count; i++) {
        info[i].decodeTimeStamp = CMTimeSubtract(info[i].decodeTimeStamp, offsetTime);
        info[i].presentationTimeStamp = CMTimeSubtract(info[i].presentationTimeStamp, offsetTime);
    }
    CMSampleBufferRef ref;
    CMSampleBufferCreateCopyWithNewTiming(nil, sampleBuffer, count, info, &ref);
    free(info);
    return ref;
}

//èŽ·å–è§†é¢‘å­˜æ”¾çš„åœ°å€
- (NSString *)videoPath {
    return [CaptureEngine getVideoPathWithName:_videoPath];
}

//åŽ‹ç¼©åŽçš„è§†é¢‘åœ°å€
-(NSString *)handledVideoPath{
    return [NSString stringWithFormat:@"%@-new.mp4",[self.videoPath substringToIndex:self.videoPath.length-4]];
}

- (NSString *)picPath {
    return [CaptureEngine getPicPathWithName:_picPath];
}

/**
 èŽ·å–åç§°ä¸ºnameçš„è§†é¢‘åœ¨æ²™ç›’ä¸­çš„å…·ä½“è·¯å¾„

 @param name æš‚å®šä¸ºå•†å“ID
 @return åç§°ä¸ºnameçš„è§†é¢‘åœ¨æ²™ç›’ä¸­çš„å…·ä½“è·¯å¾„
 */
+ (NSString *)getVideoPathWithName:(NSString *)name {
//    NSString *homePath = NSTemporaryDirectory();
    NSArray*paths =NSSearchPathForDirectoriesInDomains(NSDocumentDirectory,NSUserDomainMask,YES);
    NSString *homePath = [paths objectAtIndex:0];
    if(!homePath) {
        NSLog(@"Documentsç›®å½•æœªæ‰¾åˆ°");
        return @"";
    }
    BOOL isDir = NO;
    NSFileManager *manager = [NSFileManager defaultManager];

    BOOL exist = [manager fileExistsAtPath:homePath isDirectory:&isDir];
    //ä¸å­˜åœ¨å°±åˆ›å»º
    if (!(isDir == YES && exist == YES)) {
        [manager createDirectoryAtPath:homePath withIntermediateDirectories:YES attributes:nil error:nil];
    };
    NSString *videoPath = [NSString stringWithFormat:@"%@/%@-doubleRecord.mp4", homePath, name];
    return videoPath;
}

/**
 èŽ·å–åç§°ä¸ºnameçš„ç¬¬ä¸€å¸§å›¾ç‰‡åœ¨æ²™ç›’ä¸­çš„å…·ä½“è·¯å¾„
 
 @param name æš‚å®šä¸ºå•†å“ID
 @return åç§°ä¸ºnameçš„ç¬¬ä¸€å¸§å›¾ç‰‡åœ¨æ²™ç›’ä¸­çš„å…·ä½“è·¯å¾„
 */
+ (NSString *)getPicPathWithName:(NSString *)name {
//    NSString *homePath = NSTemporaryDirectory();
    NSArray *paths = NSSearchPathForDirectoriesInDomains(NSDocumentDirectory, NSUserDomainMask, YES);
    NSString *homePath = [paths objectAtIndex:0];
    if(!homePath) {
        NSLog(@"Documentsç›®å½•æœªæ‰¾åˆ°");
        return @"";
    }
    BOOL isDir = NO;
    NSFileManager *manager = [NSFileManager defaultManager];
    NSLog(@"%@", [manager contentsOfDirectoryAtPath:homePath error:nil]);
    BOOL exist = [manager fileExistsAtPath:homePath isDirectory:&isDir];
    //ä¸å­˜åœ¨å°±åˆ›å»º
    if (!(isDir == YES && exist == YES)) {
        [manager createDirectoryAtPath:homePath withIntermediateDirectories:YES attributes:nil error:nil];
    };
    NSString *picPath = [NSString stringWithFormat:@"%@/%@-doubleRecord.png", homePath, name];
    return picPath;
}

/**
 åˆ é™¤æœ¬åœ°å­˜å‚¨çš„è§†é¢‘å’Œå›¾ç‰‡

 @param name æš‚å®šä¸ºå•†å“ID
 */
+ (void)deleteVideoAndPicWithName:(NSString *)name {
    NSArray *paths = NSSearchPathForDirectoriesInDomains(NSDocumentDirectory, NSUserDomainMask, YES);
    NSString *homePath = [paths objectAtIndex:0];
    if(!homePath) {
        NSLog(@"Documentsç›®å½•æœªæ‰¾åˆ°");
        return;
    }
    BOOL isDir = NO;
    NSFileManager *manager = [NSFileManager defaultManager];
    NSLog(@"åˆ é™¤ä¹‹å‰%@", [manager contentsOfDirectoryAtPath:homePath error:nil]);
    BOOL exist = [manager fileExistsAtPath:homePath isDirectory:&isDir];
    //ä¸å­˜åœ¨å°±åˆ›å»º
    if (!(isDir == YES && exist == YES)) {
        return;
    };
    NSString *videoPath = [NSString stringWithFormat:@"%@/%@-doubleRecord.png", homePath, name];
    [manager removeItemAtPath:videoPath error:nil];
    NSString *picPath = [NSString stringWithFormat:@"%@/%@-doubleRecord.mp4", homePath, name];
    [manager removeItemAtPath:picPath error:nil];
    NSLog(@"åˆ é™¤ä¹‹åŽ%@", [manager contentsOfDirectoryAtPath:homePath error:nil]);
}


//å¼€å¯é—ªå…‰ç¯
-(void)flashLightOn{
    AVCaptureDevice *back = [self cameroWithPosition:AVCaptureDevicePositionBack];
    if (back.torchMode == AVCaptureTorchModeOff) {
        [back lockForConfiguration:nil];
        back.torchMode = AVCaptureTorchModeOn;

        AVCapturePhotoSettings * setting = [AVCapturePhotoSettings photoSettings];
        setting.flashMode = AVCaptureFlashModeOn;
        [back unlockForConfiguration];
    }
}

//å…³é—­é—ªå…‰ç¯
-(void)flashLightOff{
    AVCaptureDevice *back = [self cameroWithPosition:AVCaptureDevicePositionBack];
    if (back.torchMode == AVCaptureTorchModeOn) {
        [back lockForConfiguration:nil];
        back.torchMode = AVCaptureTorchModeOff;
        AVCapturePhotoSettings *setting = [AVCapturePhotoSettings photoSettings];
        setting.flashMode = AVCaptureFlashModeOff;
        [back unlockForConfiguration];
    }
}

//åˆ‡æ¢æ‘„åƒå¤´æ–¹å‘
-(void)changeCameraPositionWithCurrentIsFront:(BOOL)isFront{
    NSLog(@"åˆ‡æ¢æ‘„åƒå¤´æ–¹å‘");

    __block CATransition *animation;
    [UIView animateWithDuration:0.5 animations:^{
        animation = [CATransition animation];
        animation.duration = .5f;
        animation.timingFunction = [CAMediaTimingFunction functionWithName:kCAMediaTimingFunctionEaseInEaseOut];
        animation.type = @"oglFlip";
        [self.prewView addAnimation:animation forKey:nil];
        if (isFront) {
            animation.subtype = kCATransitionFromLeft;
            self.isDevicePositionFront = YES;

            NSLog(@"åˆ‡æ¢æ‘„åƒå¤´------å‰å˜åŽ----");
            [self.session stopRunning];
            [self.session removeInput:self.backCameraInput];

            if ([self.session canAddInput:self.frontCameraInput]) {

                [self.session addInput:self.frontCameraInput];
            }

        }else{

            animation.subtype = kCATransitionFromRight;
            self.isDevicePositionFront = NO;
            NSLog(@"åˆ‡æ¢æ‘„åƒå¤´------åŽå˜å‰----");
            [self.session stopRunning];
            [self.session removeInput:self.frontCameraInput];

            if ([self.session canAddInput:self.backCameraInput]) {
                [self.session addInput:self.backCameraInput];
            }
        }

        AVCaptureConnection *videoConnection = nil;
        for ( AVCaptureConnection *connection in [self.videoDataOut connections])
        {
            NSLog(@"%@", connection);
            for ( AVCaptureInputPort *port in [connection inputPorts] )
            {
                NSLog(@"%@", port);
                if ( [[port mediaType] isEqual:AVMediaTypeVideo] )
                {
                    videoConnection = connection;
                }
            }
        }

        if([videoConnection isVideoOrientationSupported]) // **Here it is, its always false**
        {
            [videoConnection setVideoOrientation:[UIDevice currentDevice].orientation];
        }

        [self videoMirored];

    } completion:^(BOOL finished) {
        //
        [self.session startRunning];
    }];
}

//æ ¼å¼è½¬æ¢
-(void)convertMovToMp4:(NSURL *)mediaUrl callBack:(void (^)(UIImage *stillImage, NSString *name))callBack{
    AVAsset *asset = [AVAsset assetWithURL:mediaUrl];
    AVAssetExportSession *exportSession = [AVAssetExportSession exportSessionWithAsset:asset presetName:AVAssetExportPresetLowQuality];//è®¾ç½®è¾“å‡ºåˆ†è¾¨çŽ‡
    exportSession.shouldOptimizeForNetworkUse = YES;
    exportSession.outputFileType = AVFileTypeMPEG4;
//    self.videoPath = [[self getVideoPath] stringByAppendingPathComponent:[self formatNameWithType:@"mp4"]];
    exportSession.outputURL = [NSURL fileURLWithPath:[NSString stringWithFormat:@"%@-new.mp4",[self.videoPath substringToIndex:self.videoPath.length-4]]];
    [exportSession exportAsynchronouslyWithCompletionHandler:^{
        dispatch_async(dispatch_get_main_queue(), ^{
            [self getMovieFirstFrameImageCallBack:callBack];
            if (exportSession.status == AVAssetExportSessionStatusCompleted) {
                NSLog(@"è½¬æ¢æˆåŠŸ");
            }else if (exportSession.status == AVAssetExportSessionStatusFailed){
                NSLog(@"è½¬æ¢å¤±è´¥");
            }else if (exportSession.status == AVAssetExportSessionStatusWaiting || exportSession.status == AVAssetExportSessionStatusExporting){
                NSLog(@"æ­£åœ¨è½¬æ¢");
            }else{
                NSLog(@"è½¬æ¢ä¸çŸ¥é“åœ¨å¹²å•¥");
            }
        });
    }];

}

//èŽ·å–è§†é¢‘ç¬¬ä¸€å¸§çš„å›¾ç‰‡
-(void)getMovieFirstFrameImageCallBack:(void(^)(UIImage *image, NSString *name))callBack{
    NSURL *url = [NSURL fileURLWithPath:self.videoPath];
    AVAsset *asset = [[AVURLAsset alloc]initWithURL:url options:nil];
    AVAssetImageGenerator *generator = [[AVAssetImageGenerator alloc] initWithAsset:asset];
    generator.appliesPreferredTrackTransform = true;
    CMTime thumbTime = CMTimeMakeWithSeconds(0, 60);
    generator.apertureMode = AVAssetImageGeneratorApertureModeEncodedPixels;

    [generator generateCGImagesAsynchronouslyForTimes:[NSArray arrayWithObject:[NSValue valueWithCMTime:thumbTime]] completionHandler:^(CMTime requestedTime, CGImageRef  _Nullable image, CMTime actualTime, AVAssetImageGeneratorResult result, NSError * _Nullable error) {
        if (!error) {
            if (result == AVAssetImageGeneratorSucceeded) {
                UIImage *thumbImage = [UIImage imageWithCGImage:image];
                NSData *imageData = UIImagePNGRepresentation(thumbImage);
                [imageData writeToFile:self.picPath atomically:YES];
                
                dispatch_async(dispatch_get_main_queue(), ^{
                    callBack(thumbImage,self.videoName);
                    NSLog(@"å›žè°ƒä¸€å¼ å›¾ç‰‡");
                });
            }else{
                //NSLog(@"result------%ld",(long)result);
            }
        }else{
            NSLog(@"error-----%@",error.localizedDescription);
        }
    }];
}

//å¼€å§‹å½•åˆ¶
-(void)captureEngineStartCapture{

    @synchronized(self) {
        if (!self.isCapturing) {
            self.encoder = nil;
            self.isPaused = NO;
            self.isBreaked = NO;
            _timeOffset = CMTimeMake(0, 0);
            self.isCapturing = YES;
            NSLog(@"å¼€å§‹é‡‡é›†æ•°æ®");
        }
    }
}

//åœæ­¢å½•åˆ¶---------å›žè°ƒæ–¹æ³•é‡Œè¿”å›žä¿å­˜çš„è§†é¢‘çš„åå­—
-(void)captureEngineEndCaptureWithCallBack:(void (^)(UIImage *image,NSString *name))callBack {
    //ç§»é™¤ç›‘å¬
    [[NSNotificationCenter defaultCenter] removeObserver:self name:UIApplicationDidChangeStatusBarOrientationNotification object:nil];
    NSLog(@"æ­£åœ¨å½•åˆ¶----%d",self.isCapturing);

    @synchronized (self) {
        if (self.isCapturing) {
//            NSString *path = self.encoder.path;
//            NSURL *url = [NSURL fileURLWithPath:path];
            self.isCapturing = NO;
            dispatch_async(self.queue, ^{
                [self.encoder completionWithHandler:^{
                    self.isCapturing = NO;
                    self.encoder = nil;
                    //NSLog(@"ðŸ˜‘-----åœæ­¢çš„æ—¶å€™çš„è¿›åº¦-----%f",self.currentTime/self.maxRecordTime);
                    //NSLog(@"ðŸ˜‘-----åœæ­¢çš„æ—¶å€™å½“å‰æ—¶é—´------%f",self.currentTime);
                    self.startTime = CMTimeMake(0, 0);
                    self.currentTime = 0;

//                    [[PHPhotoLibrary sharedPhotoLibrary] performChanges:^{
//                        [PHAssetChangeRequest creationRequestForAssetFromVideoAtFileURL:url];
//                    } completionHandler:^(BOOL success, NSError * _Nullable error) {
//                        if (success) {
//                            NSLog(@"ðŸ˜‘----åœæ­¢ç„¶åŽä¿å­˜æˆåŠŸ");
//                        }else{
//                            NSLog(@"ðŸ˜‘-----åœæ­¢ä½†æ˜¯ä¿å­˜å¤±è´¥%@",error);
//                        }
//                    }];
                    [self getMovieFirstFrameImageCallBack:callBack];
                }];
            });
        }
    }
}

//æš‚åœ
-(void)captureEnginePauseCapture{
    @synchronized(self) {
        if (self.isCapturing) {
            self.isPaused = YES;
            self.isBreaked = YES;
            NSLog(@"æš‚åœé‡‡é›†æ•°æ®----");
        }
    }
}

//æ¢å¤å½•åˆ¶
-(void)captureEngineResumeCapture{
    @synchronized(self) {
        if (self.isPaused) {
        NSLog(@"æ¢å¤å½•åˆ¶");
            self.isPaused = NO;
        }
    }
}

//å¼€å¯ä¼šè¯
-(void)start{
    self.startTime = CMTimeMake(0, 0);
    self.isCapturing = NO;
    self.isPaused = NO;
    self.isBreaked = NO;
    [self.session startRunning];
    NSLog(@"å¼€å¯ä¼šè¯");
}

//å…³é—­ä¼šè¯
-(void)shutDown{
    self.startTime = CMTimeMake(0, 0);
    if (self.session) {
        [self.session stopRunning];
    }
    NSLog(@"å…³é—­ä¼šè¯");
    [self.encoder completionWithHandler:^{
        NSLog(@"å…³é—­ä¼šè¯");
    }];
}



@end
